================================================================================
TTS & VOICE COMMANDS IMPLEMENTATION GUIDE - I-IMS PROJECT
================================================================================

================================================================================
SECTION 1: ALL AVAILABLE VOICE COMMANDS
================================================================================

--------------------------------------------------------------------------------
1. NAVIGATION COMMANDS (9 Routes)
--------------------------------------------------------------------------------

Command                     | What It Does              | Variations
---------------------------|---------------------------|---------------------------
"Go to dashboard"          | Navigate to Dashboard     | "open dashboard", "show dashboard", "take me to home"
"Go to alerts"             | Navigate to Alerts page   | "open alerts", "show me alerts"
"Go to inventory"          | Navigate to Inventory     | "open stock", "show inventory"
"Go to reports"            | Navigate to Reports       | "show analytics", "open reports"
"Go to orders"             | Navigate to Orders page   | "open orders", "show orders"
"Go to users"              | Navigate to Users page    | "show people", "open users"
"Go to settings"           | Navigate to Settings      | "open preferences", "show settings"
"Go to barcode scanner"    | Navigate to Scanner       | "open barcode scanner"
"Go to roles"              | Navigate to Roles         | "open roles", "show roles"

--------------------------------------------------------------------------------
2. INFORMATION COMMANDS
--------------------------------------------------------------------------------

Command                     | What It Does
---------------------------|--------------------------------------------------
"Read page"                | Speaks information about current page
"What's on this page"      | Same as "read page"

--------------------------------------------------------------------------------
3. CONTROL COMMANDS
--------------------------------------------------------------------------------

Command                     | What It Does
---------------------------|--------------------------------------------------
"Stop"                     | Stop speaking immediately
"Quiet"                    | Stop speaking
"Silence"                  | Stop speaking
"Shut up"                  | Stop speaking
"Help"                     | Shows list of available commands + speaks them
"What can I say"           | Shows help menu

--------------------------------------------------------------------------------
4. SETTINGS PAGE COMMANDS (Only work on Settings page)
--------------------------------------------------------------------------------

Command                     | What It Does
---------------------------|--------------------------------------------------
"Speak faster"             | Increases speech rate by 0.25x
"Speak slower"             | Decreases speech rate by 0.25x
"Make it louder"           | Increases volume by 10%
"Make it quieter"          | Decreases volume by 10%
"Turn on voice"            | Enables text-to-speech
"Turn off voice"           | Disables text-to-speech
"Test voice"               | Plays test message with current settings

--------------------------------------------------------------------------------
5. PLACEHOLDER COMMANDS (Not yet functional)
--------------------------------------------------------------------------------

Command                     | Status
---------------------------|--------------------------------------------------
"Generate PDF report"      | Says "feature will be implemented soon"
"Generate CSV report"      | Says "feature will be implemented soon"


================================================================================
SECTION 2: WHAT TTS CAN DO ON OUR WEBSITE
================================================================================

--------------------------------------------------------------------------------
1. PAGE NARRATION
--------------------------------------------------------------------------------

When you say "Read page", it speaks:

Dashboard:
"You are on the dashboard page. This is your main overview of the inventory system."

Alerts:
"You are on the alerts page. Here you can view critical alerts, warnings, and low stock notifications."

Inventory:
"You are on the inventory page. Manage your stock items here."

Reports:
"You are on the reports and analytics page. Generate and view inventory reports."

Orders:
"You are on the orders page. View and manage inventory orders."

Users:
"You are on the users page. Manage system users."

Roles:
"You are on the roles and access page. Configure user permissions."

Settings:
"You are on the settings page. Customize your system preferences."

Barcode Scanner:
"You are on the barcode scanner page. Scan items to quickly access or update inventory."

--------------------------------------------------------------------------------
2. NAVIGATION CONFIRMATION
--------------------------------------------------------------------------------

After every navigation command, TTS confirms:
- "Opening dashboard"
- "Opening alerts page"
- "Opening inventory"
- etc.

--------------------------------------------------------------------------------
3. SETTINGS FEEDBACK
--------------------------------------------------------------------------------

When adjusting settings via voice:
- "Speech rate set to 1.25" (when you say "speak faster")
- "Volume set to 80 percent" (when you say "make it louder")
- "Text to speech enabled" (when you turn it on)
- "Voice commands enabled/disabled"

--------------------------------------------------------------------------------
4. HELP MENU
--------------------------------------------------------------------------------

When you say "Help", it speaks:
"You can say: go to dashboard, read page, open settings, or stop to stop speaking"

And shows a visual popup with all commands.

--------------------------------------------------------------------------------
5. TEST VOICE
--------------------------------------------------------------------------------

On Settings page, click "Test Voice Settings" or say "Test voice":
"This is a test of the text to speech system. How does it sound?"

--------------------------------------------------------------------------------
6. MANUAL TTS CUSTOMIZATION (Settings Page)
--------------------------------------------------------------------------------

You can customize how TTS sounds:
- Speed: 0.5x (slow) to 2x (fast)
- Pitch: 0.5 (low) to 2 (high)
- Volume: 0% (silent) to 100% (loud)
- Voice: Choose from available system voices


================================================================================
SECTION 3: HOW OUR TTS IMPLEMENTATION WORKS
================================================================================

--------------------------------------------------------------------------------
ARCHITECTURE OVERVIEW
--------------------------------------------------------------------------------

User Voice Input
       â†“
[Microphone] â†’ [Browser's SpeechRecognition API]
       â†“
[Text Transcript] â†’ [Our useVoiceCommands Hook]
       â†“
[Pattern Matching] â†’ [Command Execution]
       â†“
[useTTS Hook] â†’ [Browser's SpeechSynthesis API]
       â†“
[Speakers] â†’ User Hears Response

--------------------------------------------------------------------------------
COMPONENT 1: useTTS Hook
--------------------------------------------------------------------------------

File: frontend/src/hooks/useTTS.ts

What it does:
Provides text-to-speech functionality using the browser's native SpeechSynthesis API.

How it works:

STEP 1: Initialize
const { speak, stop, isSpeaking, voices } = useTTS();

STEP 2: When you call speak(text):
speak("Hello world");

Behind the scenes:

1. Creates an Utterance Object
   const utterance = new SpeechSynthesisUtterance("Hello world");

2. Applies Settings
   utterance.rate = 1;      // Speed (0.5 - 2)
   utterance.pitch = 1;     // Pitch (0.5 - 2)
   utterance.volume = 1;    // Volume (0 - 1)
   utterance.voice = null;  // Uses default voice

3. Sets Up Event Handlers
   utterance.onstart = () => setIsSpeaking(true);   // Update UI
   utterance.onend = () => setIsSpeaking(false);     // Update UI
   utterance.onerror = (e) => console.error(e);      // Handle errors

4. Sends to Browser
   window.speechSynthesis.speak(utterance);

5. Browser Processing:
   - Browser sends utterance to OS text-to-speech engine
   - OS converts text to audio waveform
   - Audio plays through speakers
   - Event fires when complete

STEP 3: State Management
const [isSpeaking, setIsSpeaking] = useState(false);
const [isPaused, setIsPaused] = useState(false);

These track the current state so your UI can show:
- Gray mic icon (dormant)
- Blue pulsing mic (listening)
- Bouncing speaker icon (speaking)

--------------------------------------------------------------------------------
COMPONENT 2: useVoiceCommands Hook
--------------------------------------------------------------------------------

File: frontend/src/hooks/useVoiceCommands.ts

What it does:
Listens to your voice and matches it to predefined commands.

How it works:

STEP 1: Initialize SpeechRecognition
const recognition = new webkitSpeechRecognition(); // Chrome/Edge
recognition.continuous = false;  // Stop after one command
recognition.interimResults = true; // Show text as you speak
recognition.lang = 'en-US';      // English

STEP 2: Define Commands
const commands = [
  {
    command: /go to (dashboard|alerts|inventory)/i, // Regex pattern
    action: (matches) => {
      const page = matches[1]; // Extract "dashboard" or "alerts" etc.
      navigate(`/${page}`);    // Navigate to that page
      speak(`Opening ${page}`); // Confirm with audio
    }
  }
];

STEP 3: Start Listening
When you click the voice button:
startListening() â†’ recognition.start();

What happens:
1. Microphone activates (browser asks permission first time)
2. Browser records audio
3. Audio sent to Google Cloud Speech API (Chrome/Edge)
4. AI converts audio to text
5. Text returned as "transcript"

STEP 4: Real-Time Transcription
As you speak:

recognition.onresult = (event) => {
  let interim = "";  // Text as you're speaking
  let final = "";    // Final text when you finish
  
  for (let result of event.results) {
    if (result.isFinal) {
      final += result[0].transcript; // Complete sentence
    } else {
      interim += result[0].transcript; // Partial text
    }
  }
  
  setInterimTranscript(interim); // Show in UI
  setTranscript(final);          // Process command
};

Example:
- You say: "Go to..."
- Interim: "go to" (shows in real-time)
- You say: "...dashboard"
- Final: "go to dashboard" (command executes)

STEP 5: Pattern Matching
When final transcript is received:

const fullTranscript = "go to dashboard".toLowerCase();

// Check each command
commands.forEach(cmd => {
  if (typeof cmd.command === 'string') {
    // Simple string match
    if (fullTranscript.includes(cmd.command.toLowerCase())) {
      cmd.action(); // Execute!
    }
  } else if (cmd.command instanceof RegExp) {
    // Regex match (more flexible)
    const matches = fullTranscript.match(cmd.command);
    if (matches) {
      cmd.action(matches); // Execute with captured groups!
    }
  }
});

Example Regex Breakdown:
/go to (dashboard|alerts|inventory)/i

- "go to" - Must say these words
- "(dashboard|alerts|inventory)" - One of these (captured in group)
- "i" - Case insensitive

Matches:
- âœ“ "Go to dashboard"
- âœ“ "GO TO ALERTS"
- âœ“ "go to inventory"
- âœ— "show dashboard" (doesn't start with "go to")

STEP 6: Execute Action
action: (matches) => {
  const page = matches[1];        // "dashboard"
  navigate(`/${page}`);           // React Router navigates
  speak(`Opening ${page}`);       // TTS confirms
}

--------------------------------------------------------------------------------
COMPONENT 3: VoiceControlButton
--------------------------------------------------------------------------------

File: frontend/src/components/VoiceControlButton.tsx

What it does:
The microphone button in the header that ties everything together.

How it works:

STEP 1: Setup
const { speak, stop, isSpeaking } = useTTS();
const { isListening, startListening, stopListening } = useVoiceCommands(commands);

STEP 2: Click Handler
const handleClick = () => {
  if (isSpeaking) {
    stop();              // Stop talking
  } else if (isListening) {
    stopListening();     // Stop listening
  } else {
    startListening();    // Start listening
  }
};

STEP 3: Visual States
{isSpeaking ? (
  <Volume2 className="animate-bounce" /> // ğŸ”Š Bouncing speaker
) : isListening ? (
  <Mic className="animate-pulse" />      // ğŸ¤ Pulsing mic (blue)
) : (
  <Mic className="text-gray-600" />      // ğŸ¤ Gray mic (dormant)
)}

STEP 4: Active Indicator Dot
{(isListening || isSpeaking) && (
  <span className="absolute top-1 right-1 w-2 h-2 bg-blue-500 rounded-full animate-pulse" />
)}

Small blue dot in corner when active.


================================================================================
SECTION 4: COMPLETE USER FLOW EXAMPLE
================================================================================

Scenario: User wants to navigate to Alerts page using voice

STEP-BY-STEP:

1. User clicks microphone button
   VoiceControlButton.handleClick() called
   â†’ startListening()
   â†’ recognition.start()
   â†’ Microphone activates
   â†’ Icon changes to pulsing blue mic
   â†’ Blue dot appears

2. User says "Go to alerts"
   Microphone captures audio
   â†’ Audio sent to Google Cloud
   â†’ AI processes: "go to alerts"
   â†’ recognition.onresult fires
   â†’ Transcript: "go to alerts"

3. Pattern matching
   Check commands array
   â†’ Match found: /go to (?:the )?alerts?/i
   â†’ Extract: "alerts"
   â†’ Execute action function

4. Navigation
   navigate('/alerts')
   â†’ React Router changes page
   â†’ Browser URL: /alerts
   â†’ Alerts page loads

5. Audio confirmation
   speak('Opening alerts page')
   â†’ Creates SpeechSynthesisUtterance
   â†’ Browser TTS engine speaks
   â†’ User hears: "Opening alerts page"
   â†’ Icon changes to bouncing speaker

6. Completion
   utterance.onend fires
   â†’ isSpeaking = false
   â†’ Icon returns to gray mic (dormant)
   â†’ Blue dot disappears
   â†’ Ready for next command


================================================================================
SECTION 5: SETTINGS PERSISTENCE
================================================================================

File: frontend/src/pages/Settings.tsx

How settings are saved:

// Load from localStorage on mount
const [settings, setSettings] = useState<VoiceSettings>(() => {
  const saved = localStorage.getItem('voiceSettings');
  return saved ? JSON.parse(saved) : defaultSettings;
});

// Save to localStorage whenever changed
useEffect(() => {
  localStorage.setItem('voiceSettings', JSON.stringify(settings));
}, [settings]);

What this means:
- Settings saved in browser's localStorage
- Persists across page refreshes
- Persists even if you close browser
- Unique to each user/browser
- Not synced to backend (yet)


================================================================================
SECTION 6: KEY TECHNICAL FEATURES
================================================================================

1. ZERO EXTERNAL DEPENDENCIES
   - Uses native Web APIs
   - No react-speech-kit or external libraries
   - Smaller bundle size
   - No API keys needed

2. TYPE-SAFE
   interface VoiceCommand {
     command: string | RegExp;
     action: (matches?: string[]) => void;
     description?: string;
   }
   Full TypeScript support with proper interfaces.

3. ERROR HANDLING
   recognition.onerror = (event) => {
     setError(event.error);
     console.error('Speech recognition error:', event.error);
   };

4. BROWSER DETECTION
   const isSupported = 'webkitSpeechRecognition' in window;
   if (!isSupported) return null; // Don't show button

5. CONTEXT-AWARE
   const location = useLocation();
   // Commands know which page you're on


================================================================================
SECTION 7: DATA FLOW DIAGRAM
================================================================================

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   User      â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ Clicks mic button
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ VoiceControlButton  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ startListening()
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ useVoiceCommands    â”‚ â†â”€â”€â”
â”‚  Hook               â”‚    â”‚ 
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚ Commands array
       â”‚ recognition.start()â”‚
       â–¼                    â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚ Browser Microphone  â”‚    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
       â”‚ Audio stream      â”‚
       â–¼                    â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚ Google Cloud API    â”‚    â”‚
â”‚ (Chrome/Edge)       â”‚    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
       â”‚ Transcript        â”‚
       â–¼                    â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚ Pattern Matching    â”‚â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ Command matched
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Execute Action      â”‚
â”‚ - navigate()        â”‚
â”‚ - speak()          â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ speak(text)
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ useTTS Hook         â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ SpeechSynthesis
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ OS TTS Engine       â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ Audio output
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Speakers ğŸ”Š         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


================================================================================
SECTION 8: BROWSER COMPATIBILITY
================================================================================

--------------------------------------------------------------------------------
TEXT-TO-SPEECH (Works Everywhere)
--------------------------------------------------------------------------------

Browser Support:
âœ“ Chrome/Edge - Full support
âœ“ Safari - Full support
âœ“ Firefox - Full support
âœ“ Opera - Full support

Why it works everywhere:
- SpeechSynthesis API is a W3C Standard
- All major browsers have implemented it
- Part of Web Speech API specification (since 2012)
- Uses operating system's built-in text-to-speech engine

How it works:
1. Your code calls window.speechSynthesis.speak(utterance)
2. Browser uses the OS's built-in text-to-speech engine
3. OS converts text to audio
4. Browser plays the audio through speakers

--------------------------------------------------------------------------------
VOICE RECOGNITION (Chrome/Edge Only)
--------------------------------------------------------------------------------

Browser Support:
âœ“ Chrome - Full support
âœ“ Edge - Full support (uses Chromium engine)
âœ— Safari - Very limited/experimental
âœ— Firefox - Not supported
âœ— Opera - Not supported

Why it DOESN'T work everywhere:

1. NO STANDARD IMPLEMENTATION
   - SpeechRecognition API is NOT a finalized web standard
   - Still in "draft" status at W3C
   - Browser vendors not required to implement it

2. TECHNICAL COMPLEXITY
   Voice recognition is much harder than text-to-speech:
   - TTS: Text â†’ Audio (one direction, deterministic)
   - Voice: Audio â†’ Text (requires AI/ML, language models, cloud processing)

3. PRIVACY CONCERNS
   Voice recognition requires:
   - Microphone access
   - Audio data processing
   - Often cloud services for accuracy
   Browsers are cautious about features that could invade privacy

4. VENDOR-SPECIFIC IMPLEMENTATION
   Chrome/Edge use Google's speech recognition engine:
   - Proprietary technology
   - Requires Google Cloud Speech API backend
   - Only available in Chromium-based browsers

Technical Process (Chrome/Edge):
1. Microphone captures audio
2. Audio sent to Google Cloud Speech-to-Text API
3. Google's AI processes it
4. Text returned to browser
5. Your code receives the transcript

Why Others Don't Support It:
- Firefox: Doesn't want Google dependency
- Safari: Working on their own implementation (slow progress)
- Privacy concerns: Sending audio to Google servers

--------------------------------------------------------------------------------
COMPARISON TABLE
--------------------------------------------------------------------------------

Feature              | Chrome | Edge  | Safari | Firefox
---------------------|--------|-------|--------|----------
Text-to-Speech       | âœ“      | âœ“     | âœ“      | âœ“
Voice Recognition    | âœ“      | âœ“     | âœ—      | âœ—
Offline TTS          | âœ“      | âœ“     | âœ“      | âœ“
Offline Voice        | âœ—      | âœ—     | âœ—      | âœ—
Cloud Processing     | Voice  | Voice | N/A    | N/A


================================================================================
SECTION 9: SUMMARY
================================================================================

--------------------------------------------------------------------------------
WHAT USERS CAN DO
--------------------------------------------------------------------------------

- Navigate to any page via voice (9 routes)
- Get information about current page
- Stop/start TTS at any time
- Customize voice settings (speed, pitch, volume)
- Control settings via voice commands
- Get help menu showing all commands

--------------------------------------------------------------------------------
HOW IT WORKS TECHNICALLY
--------------------------------------------------------------------------------

1. VoiceControlButton - UI component with click handler
2. useVoiceCommands - Captures voice â†’ converts to text â†’ matches patterns
3. Pattern Matching - Regex matches transcript to commands
4. Action Execution - Runs navigate() or speak()
5. useTTS - Converts text â†’ audio using OS engine
6. Settings - Saved in localStorage, persist across sessions

--------------------------------------------------------------------------------
KEY TECHNOLOGIES
--------------------------------------------------------------------------------

- Web Speech API (SpeechSynthesis + SpeechRecognition)
- React Hooks (useState, useEffect, useCallback, useRef)
- TypeScript for type safety
- React Router for navigation
- localStorage for persistence

--------------------------------------------------------------------------------
FILES CREATED/MODIFIED
--------------------------------------------------------------------------------

NEW FILES:
- frontend/src/hooks/useTTS.ts
- frontend/src/hooks/useVoiceCommands.ts
- frontend/src/components/VoiceControlButton.tsx

MODIFIED FILES:
- frontend/src/layout/Header.tsx (added VoiceControlButton)
- frontend/src/pages/Settings.tsx (enhanced with TTS settings)

--------------------------------------------------------------------------------
PROJECT STATS
--------------------------------------------------------------------------------

Total Voice Commands: 15+
Navigation Routes: 9
Settings Options: 6 (rate, pitch, volume, voice, TTS toggle, voice commands toggle)
Browser Support: TTS (all), Voice (Chrome/Edge only)
External Dependencies: 0 (uses native APIs)
Lines of Code: ~500 across all files


================================================================================
END OF DOCUMENTATION
================================================================================
Generated: 2025
Project: I-IMS (Inclusive Inventory Management System)
Developer: Aaditya Joshua Srivastava
Role: Audio Software Engineer (TTS & Voice Commands)
================================================================================